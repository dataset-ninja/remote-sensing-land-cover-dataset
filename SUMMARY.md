**LoveDA: Land-cOVEr Domain Adaptive Semantic Segmentation** is a dataset for a semantic segmentation task. It is used in the geospatial domain. 

The dataset consists of 5987 images with 20658 labeled objects belonging to 7 different classes including *background*, *road*, *building*, and other: *forest*, *water*, *agriculture*, and *barren*.

Images in the LoveDA dataset have pixel-level semantic segmentation annotations. There are 1796 (30% of the total) unlabeled images (i.e. without annotations). There are 3 splits in the dataset: *train* (2522 images), *test* (1796 images), and *val* (1669 images). Alternatively, the dataset could be split into 2 areas: ***rural*** (2358 images) and ***urban*** (1833 images). The dataset was released in 2021 by the Wuhan University, China.

Here are the visualized examples for the classes:

[Dataset classes](https://github.com/dataset-ninja/remote-sensing-land-cover-dataset/raw/main/visualizations/classes_preview.webm)
